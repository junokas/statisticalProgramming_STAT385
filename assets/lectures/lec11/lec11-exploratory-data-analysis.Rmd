---
title: "Lecture 11: Exploratory Data Analysis - Part 1"
author: "STAT 385 - James Balamuta"
date: "July 12, 2016"
output:
  beamer_presentation:
  highlight: default
---

```{r setup, include=FALSE}
options(width = 60)
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
```

```{r, echo = F, message=F, cache = FALSE}
library("magrittr")
library("ggplot2")
```

# On the Agenda

1. Administrative Issues
    - HW4 Assigned Tonight
    - Graded Exams available for pick up tomorrow during Office Hour
2. Exploratory Data Analysis
    - Quantitative
    - Intro to Visual

# Starting an Analysis

> "When one begins an analysis, the facts of the analysis will *stick* to oneself."
>
> --- James Balamuta

What does it mean that the "facts" are **sticking** to them?

# Exploratory Data Analysis

**Exploratory Data Analysis (EDA)** is a philosophy for data analysis that employs a variety of techniques that are primarily visual but sometimes quantitative pioneered by John Tukey in his 1977 book [Exploratory Data Analysis](https://www.amazon.com/Exploratory-Data-Analysis-John-Tukey/dp/0201076160)
$$ $$
The goals are to:

- understand the structure of the data;
- detect mistakes in importing data or within the dataset;
- find outliers and anomalies; and
- test underlying assumptions;

# Variable Types in Statistics

Unlike in *Base R*, Statistics views data stored in variables in two forms:

- Quantitative 
    - A *number* that describes an outcome
        - **Discrete**: Integers  e.g.  1 brother, 2 Starbucks Drinks
        - **Continuous**: Real number e.g. **86.25** on a test, $\pi = 3.141593\ldots$
- Categorical
    - A *string* that describes a trait
        - e.g. "Male" or "Female", "Student" or "Instructor", "Ninjas" or "Pirates"

# Sample data

To investigate this, we're going to simulate some data that might be
commonly associated with an experiment

```{r}
# Make some data
n = 20

# Set seed for reproducibility
set.seed(1133)
d = data.frame(id = paste0("s",sample(1:n, n)),
               sex = sample(c("male","female"), 
                            n, replace = T),
               food = sample(c("cake","pie"),
                             n, replace = T),
               trt_a = runif(n),
               trt_b = rnorm(n)
               )
```

# Verify the Data

The first step to this process is to verify the `data`. 

To do so, use:

- `head()` and `tail()` 
    - to make sure the data has been imported correctly.
- `nrow()` and `ncol()` OR `dim()`
    - to understand the amount of observations and variables.
- `class`
    - to verify import data type of each variable.
- `is.na`
    - to obtain whether missing values exist.

# Verify the Data - Head

```{r verify_head}
head(d)        # Defaults to showing the first 6 

head(d, n = 2) # Shows the first 2 
```

# Verify the Data - Tail

```{r verify_tail}
tail(d)        # Defaults to showing the last 6 

tail(d, n = 2) # Shows the last 2 
```

# Verify the Data - Observations and Variables

```{r verify_obs_and_vars}
nrow(d)  # Find the number of observations
ncol(d)  # Find the number of variables 
dim(d)   # Both observations and variables (n x p)
```

# Verify the Data - Check Data Types

```{r verify_data_types}
sapply(d, FUN=class)   # Obtain each columns data type
```

# Verify the Data - Missing Values

```{r verify_missing_sum_func}
# Count number of missing values
sum_na = function(x){
  sum(is.na(x))
}
```

```{r verify_missing_sum_overview}
sapply(d, FUN=sum_na)   # Missing values per column
```

# Types of EDA

There are two types of EDA:

- Quantitative
- Visual

Both with *ups* and *downs*.

# Univariate **Quantitative** Analysis

Depending on the *data type* there are different ways of obtaining
univariate **quantitative** information

- **numeric** 
    - 5 Summary
- **categorical**
    - frequency
    - contigency table

# Univariate **Quantitative** Analysis - Numeric

The 5 Summary Statistics are defined as follows:

- **Minimum**
    - `min()`
- **1st Quartile** or **25% Quantile**
    - `quantile(x, probs = 0.25)`
- **2nd Quartile** or **50% Quantile** 
    - `median()`
- **3rd Quartile** or **75% Quantile:** 
    - `quantile(x, probs = 0.75)`
- **Maximum:** 
    - `max()`
- **(*Optional*) Mean:** 
    - `mean()`


# Univariate **Quantitative** Analysis - Numeric

Quick implementation

```{r numeric_5}
stat5summary = function(x, na.rm = T){
  if(class(x) != "numeric") 
    stop("`x` must be numeric data")
  
  # Calculate quantiles
  q = quantile(x, probs = c(0.25, 0.5, 0.75),
               na.rm = na.rm)

  # Return
  c("min" = min(x, na.rm = na.rm),
    "q1" = q[[1]], "median" = q[[2]], "q3" = q[[3]], 
    "max" = max(x, na.rm = na.rm))
}
```

What might we want to add here? 

# Univariate **Quantitative** Analysis - Numeric

Let's try out our function!

```{r numeric_5_call}
sapply(d[,4:5], FUN = stat5summary) 
```

# Univariate **Quantitative** Analysis - Numeric

Psst... the `summary()` function does this by default on `numeric` data!

```{r numeric_5_call_summary}
sapply(d[,4:5], FUN = summary) 
```

# Univariate **Quantitative** Analysis - Categorical

Categorical data normally is associated with:

- Frequency Counts
- Table Format $x$ vs. $y$
- Percentages

# Univariate **Quantitative** Analysis - Categorical

```{r category_count}
sapply(d[,1:3], FUN = summary) 
```


# Univariate **Quantitative** Analysis - Categorical Tabulate

Overall counts between two variables

```{r category_table}
(o = table(d[,2], d[,3]))
```


# Univariate **Quantitative** Analysis - Categorical Proportions

Element / Total number of observations

```{r category_percentages}
prop.table(o)  # Requires table() object
```
    

# Univariate **Quantitative** Analysis - Categorical Headache

Make sure to avoid unique comparisons...

```{r category_table_error}
head(table(d[,1], d[,2]))
```

# Rules of Thumb

There are a couple *rules of thumb* that are slightly helpful with EDA and 
statistical modeling.

1. If the number of distinct numbers is less than 20, treat them as *categorical* 
variables.
2. Try to floor and cap *numerical* values to avoid large extrema. 
    - Floor and Cap means to set a boundary point for low and high values.
    - Never tell a robust statistician this...


# Exercises

1. Determine the summary information for the `PlantGrowth` dataset.
    - What variables exist, what kind of variables are there? 
2. Obtain the `msos` package from cran and look at the `spam` dataset.
    - How often was spam detected?
3. Download the `faraway` package from CRAN and explore the `pima` dataset.
    - Any pattern with missing values? 

# Univariate **Visual** Analysis

> "The greatest value of a picture is when it forces us to notice what we never expected to see."
>
> --- John Tukey in Exploratory Data Analysis (1977)

# A sample data generation

```{r sample_data}
set.seed(2016) # Set Seed for reproducibility
n = 1e4        # Number of observations

(n*2) %>%      # Generate some data
  rnorm %>%
  matrix(ncol = 2) -> a

runif(n, 0, 2 * pi) %>%
  {0.5 * cbind(sin(.), cos(.))} -> b
  
o = rbind(a,b)   # Combine generate data

x = as.data.frame(o[sample(nrow(o)), ])

colnames(x) = c("x","y")
```

Do you know what is happening?

# Numerically we have...

```{r sample_data_summary}
summary(x)    # data.frame implements summary.
```

Insight: Data looks to be bounded between -4 and 4.

# Graphically we have ... 

```{r ggplot_exploratory}
ggplot(x) + geom_point(aes(x,y))
```

# Redux of Graphically we have ... 

```{r ggplot_exploratory_redux}
ggplot(x) + geom_point(aes(x,y), alpha = 0.05)
```

# A note...

- Notice in the previous slides, there was no call to `plot()`. 
- Instead, `ggplot()` was used to create the graphic through the use of layering via the `+` symbol.  
- To do the same with base *R*, we would of used:

```{r base_r_exploratory, fig.height = 5}
plot(x, col = rgb(0, 0, 0, 0.05)) # Transparent color
```

